{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should solve the MNIST problems and be able to recognize digit thanks to AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each image into tensor ( numpy array => Tensor )\n",
    "# Normalize data to win time in gradient descent\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# define batch size to regroup all images into slot of 64 images\n",
    "batch_size = 64\n",
    "\n",
    "# set train loader\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('../data', train=True, download=True, transform=transform), batch_size=batch_size)\n",
    "# set test loader\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('../data', train=False, download=True, transform=transform), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random weight for prediction\n",
    "weight = torch.randn(784, 10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(weights, test_loader):\n",
    "    test_size = len(test_loader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        # reshape each image, to follow generate activation value\n",
    "        data = data.view((-1, 28*28))\n",
    "        \n",
    "        # generate activation value for each neuron\n",
    "        outputs = torch.matmul(data, weights)\n",
    "        \n",
    "        # Transform value between 0 and 1\n",
    "        softmax = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get the highest value / prediction\n",
    "        pred = softmax.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        # calculate the number of good predictions to make an average\n",
    "        n_correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        correct += n_correct\n",
    "\n",
    "    acc = correct / test_size # make average\n",
    "    print(\" Accuracy on test set\", acc)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shape: 1.77189302444458452 Accuracy on test set 0.8537\n",
      "Loss shape: 2.19386982917785646 Accuracy on test set 0.8594\n",
      "Loss shape: 0.86868327856063845 Accuracy on test set 0.8653\n",
      "Loss shape: 1.52300310134887755 Accuracy on test set 0.8651\n",
      "Loss shape: 2.04420590400695867 Accuracy on test set 0.8656\n",
      "Loss shape: 0.75222319364547734 Accuracy on test set 0.8635\n",
      "Loss shape: 1.61993575096130377 Accuracy on test set 0.8656\n",
      "Loss shape: 1.47390568256378175 Accuracy on test set 0.867\n",
      "Loss shape: 0.77408719062805183 Accuracy on test set 0.8677\n",
      "Loss shape: 0.807728052139282267"
     ]
    }
   ],
   "source": [
    "# train AI\n",
    "\n",
    "def train_ai(weight, train_loader):\n",
    "    it = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Reset my weight\n",
    "        if weight.grad is not None:\n",
    "            weight.grad.zero_()\n",
    "\n",
    "        # reshape each image, to follow generate activation value\n",
    "        data = data.view((-1, 28*28))\n",
    "        \n",
    "        # Get output of 10 neuron / prediction\n",
    "        outputs = torch.matmul(data, weight)\n",
    "\n",
    "        # Calculate loss\n",
    "        log_softmax = F.log_softmax(outputs, dim=1)\n",
    "        loss = F.nll_loss(log_softmax, targets)\n",
    "        print(\"\\rLoss shape: {}\".format(loss), end=\"\")\n",
    "\n",
    "        # Backtracking, to minimize error\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            weight -= 0.1*weight.grad\n",
    "\n",
    "        it += 1\n",
    "        if it % 100 == 0:\n",
    "            test(weight, test_loader)\n",
    "\n",
    "        if it > 5000:\n",
    "            break\n",
    "            \n",
    "train_ai(weight, train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre est 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get test data\n",
    "batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "data = data.view((-1, 28*28))\n",
    "\n",
    "outputs = torch.matmul(data, weight)\n",
    "softmax = F.softmax(outputs, dim=1)\n",
    "pred = softmax.argmax(dim=1, keepdim=True)\n",
    "\n",
    "plt.imshow(data[16].view(28, 28), cmap=\"gray\")\n",
    "print(\"Le nombre est\", int(pred[16]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
